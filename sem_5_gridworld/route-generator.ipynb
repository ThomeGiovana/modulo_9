{"cells":[{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":240,"status":"ok","timestamp":1710730657526,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"},"user_tz":180},"id":"gPHKMo9Qobx7"},"outputs":[],"source":["import random\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"mv69B2Lwm9ta"},"source":["# 1. Criação do grid"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1710730657957,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"},"user_tz":180},"id":"fL6R8C1ToGhI"},"outputs":[],"source":["def randomCell():\n","  line = random.randint(0, 7)\n","  col = random.randint(0, 7)\n","  return [line, col]"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1710730657957,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"},"user_tz":180},"id":"pPV-UhqZ-oJF"},"outputs":[],"source":["def gridInit():\n","\n","  grid = []\n","  currentLineList = []\n","  lines = 8\n","  cols = 8\n","  currentLine = 1\n","  currentCol = 1\n","\n","  # percorre linha por linha\n","  while currentLine <= lines:\n","    while currentCol <= cols:\n","      currentLineList.append({\n","          \"valueUp\": 0,\n","          \"valueDown\": 0,\n","          \"valueLeft\": 0,\n","          \"valueRight\": 0,\n","          \"type\": \"-\"\n","          })\n","      currentCol += 1\n","    grid.append(currentLineList)\n","    currentLineList = []\n","    currentLine += 1\n","    currentCol = 1 # reseta a coluna pro início cada vez que a linha muda\n","\n","  # colocando célular randômicas\n","  randomStart = randomCell()\n","  randomEnd = randomCell()\n","  randomMountain = randomCell()\n","  randomQuicksand = randomCell()\n","  grid[randomStart[0]][randomStart[1]][\"type\"] = \"S\"\n","  grid[randomEnd[0]][randomEnd[1]][\"type\"] = \"E\"\n","  grid[randomMountain[0]][randomMountain[1]][\"type\"] = \"M\"\n","  grid[randomQuicksand[0]][randomQuicksand[1]][\"type\"] = \"Q\"\n","\n","  return grid, randomStart, randomEnd, randomMountain, randomQuicksand"]},{"cell_type":"markdown","metadata":{"id":"emgXrL4TnKNH"},"source":["# 2. Print do grid"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1710730657958,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"},"user_tz":180},"id":"ckK6ZEltnM3-"},"outputs":[],"source":["def gridPrint(grid):\n","  currentLine = 0\n","  currentCol = 0\n","  while currentLine < 8:\n","    strLine = \"\"\n","    while currentCol < 8:\n","      strLine += grid[currentLine][currentCol][\"type\"] + \" \"\n","      currentCol += 1\n","    print(strLine)\n","    currentCol = 0\n","    currentLine += 1"]},{"cell_type":"markdown","metadata":{"id":"-uZuj6R9vkOe"},"source":["# 3. Conjunto de ações que o agente pode realizar\n","O ambiente assume que o agente não pode tomar a decisão de ir para fora do grid ou mover-se para uma posição de montanha. Essas ações não estarão disponíveis para escolha dependendo de sua posição.\n","Se, por acaso, o número de montanhas aumentar, a função `availableActions()` contempla + de uma montanha por grid.\n","A função não contempla grids diferentes de 8x8, o código teria que ser editado para isso."]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1710730657958,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"},"user_tz":180},"id":"p7fdGLnUvoeP"},"outputs":[],"source":["def availableActions(agentPosition, mountainPosition):\n","  # positions têm forma [line, col]\n","  up = True\n","  down = True\n","  left = True\n","  right = True\n","\n","  # handle de linhas e colunas limites\n","  if agentPosition[1] == 7: # se está na col 7\n","    right = False\n","  elif agentPosition[1] == 0: # se está na col 0\n","    left = False\n","  if agentPosition[0] == 0: # se está na line 0\n","    up = False\n","  elif agentPosition[0] == 7:\n","    down = False\n","\n","  # handle de mountain\n","  mountainLine = mountainPosition[0]\n","  mountainCol = mountainPosition[1]\n","  if agentPosition[0] + 1 == mountainLine: # se a montanha está em baixo do agente\n","    down = False\n","  if agentPosition[0] - 1 == mountainLine: # se a montanha está em cima do agente\n","    up = False\n","  if agentPosition[1] + 1 == mountainCol: # se a montanha está à direita do agente\n","    right = False\n","  if agentPosition[1] - 1 == mountainCol: # se a montanha está à esquerda do agente\n","    left = False\n","\n","  return up, down, left, right"]},{"cell_type":"markdown","metadata":{"id":"ZpisPp0E1gwS"},"source":["# 4. Recompensas\n","- Entrar na areia movediça = -10\n","- Mover-se para qualquer posição que não seja final = -1\n","- Mover-se para estado final = +100\n"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1710730657958,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"},"user_tz":180},"id":"9zwKO0oH1kaj"},"outputs":[],"source":["def rewardBasedOnAction(action, agentPosition, randomEnd, randomQuicksand):\n","  if action == 0: # up\n","    newPosition = agentPosition[0] - 1\n","  elif action == 1: # down\n","    newPosition = agentPosition[0] + 1\n","  elif action == 2: # left\n","    newPosition = agentPosition[1] - 1\n","  elif action == 3: # right\n","    newPosition = agentPosition[1] + 1\n","  else:\n","    raise ValueError(\"Action out of range\")\n","\n","  if newPosition == randomEnd:\n","    return newPosition, +100\n","  elif newPosition == randomQuicksand:\n","    return newPosition, -10\n","  else:\n","    return newPosition, -1"]},{"cell_type":"markdown","metadata":{"id":"KNMpiKnBVEmw"},"source":["# Atualização de qualidades com Q-learning\n","O agente tentará aprender a melhor política utilizando o algoritmo Q-learning"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1710730657958,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"},"user_tz":180},"id":"DPf9QxJkVKTT"},"outputs":[],"source":["def updateCellQuality(oldQuality, reward, maxNextActionValue):\n","  # parâmetros do q-learning\n","  discountFactor = 0.9\n","  learningRate = 0.1\n","  return oldQuality + (learningRate * (reward + (discountFactor * maxNextActionValue) - oldQuality))"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1710730657958,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"},"user_tz":180},"id":"Y7L_J3SyXlaU"},"outputs":[],"source":["def actionChooser(grid, up, down, left, right):\n","  exploitationRate = 60 # em %\n","  whatWillIDo = random.randint(1, 100)\n","  if whatWillIDo >= exploitationRate: # explora\n","    isRandomActionPossible = False\n","    # fica sorteando uma ação enquanto a sorteada não é possível com base nos parâmetros booleanos da função\n","    while isRandomActionPossible == False:\n","      action = random.randint(0, 3)\n","      if action == 0:\n","        if up == False:\n","          pass\n","        else:\n","          isRandomActionPossible = True\n","      elif action == 1:\n","        if down == False:\n","          pass\n","        else:\n","          isRandomActionPossible = True\n","      elif action == 2:\n","        if left == False:\n","          pass\n","        else:\n","          isRandomActionPossible = True\n","      elif action == 3:\n","        if right == False:\n","          pass\n","        else:\n","          isRandomActionPossible = True\n","\n","  else: # exploita\n","    # seleciona a maior qualidade de estado/ação\n","\n","\n","  return action"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1710730657958,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"},"user_tz":180},"id":"8lpyN_G7YqVu"},"outputs":[],"source":["def maxNextStateActionQualityCalculator(grid, nextPosition):\n","  goingUp = grid[nextPosition[0]][nextPosition[1]][\"valueUp\"]\n","  goingDown = grid[nextPosition[0]][nextPosition[1]][\"valueDown\"]\n","  goingLeft = grid[nextPosition[0]][nextPosition[1]][\"valueLeft\"]\n","  goingRight = grid[nextPosition[0]][nextPosition[1]][\"valueRight\"]\n","  allValues = [goingUp, goingDown, goingLeft, goingRight]\n","  return np.argmax(allValues)"]},{"cell_type":"markdown","metadata":{"id":"Gtk6kQjOqQcv"},"source":["# Execução do ambiente"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1710730657958,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"},"user_tz":180},"id":"58EwBofYqTb1","outputId":"e28faeda-3dd8-4e7d-ccf2-5b8ea64adb9f"},"outputs":[{"name":"stdout","output_type":"stream","text":["- - - - - - - - \n","- - - - - - - - \n","- - - - - - - - \n","- - - - - Q S - \n","- - - - - - - E \n","- - - - - - - - \n","- - - - - - - M \n","- - - - - - - - \n"]}],"source":["# inicialização do ambiente\n","grid, randomStart, endPosition, mountainPosition, quicksandPosition = gridInit()\n","gridPrint(grid)"]},{"cell_type":"markdown","metadata":{"id":"lv_uV-cNYSCd"},"source":["## Rodando Q-learning"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1710730657958,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"},"user_tz":180},"id":"hqjkeUIyZzTq"},"outputs":[],"source":["def turnActionToString(action):\n","  if action == 0:\n","    return \"valueUp\"\n","  elif action == 1:\n","    return \"valueDown\"\n","  elif action == 2:\n","    return \"valueLeft\"\n","  elif action == 3:\n","    return \"valueRight\""]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1710730657959,"user":{"displayName":"Giovana Thome","userId":"04171346351423178730"},"user_tz":180},"id":"qeupJbLdYRkk"},"outputs":[],"source":["agentPosition = randomStart\n","# actions up, down, left, right -> 0, 1, 2, 3\n","\n","iterations = 100\n","qualityTable = []\n","\n","for i in iterations:\n","  # finds the available actions for the current position\n","  up, down, left, right = availableActions(agentPosition, randomMountain)\n","\n","  # chooses hte action based\n","  action = actionChooser(grid, up, down, left, right)\n","  nextPosition, reward = rewardBasedOnAction()\n","  maxNextStateActionQuality = maxNextStateActionQualityCalculator(grid, nextPosition)\n","\n","  # utiliza as informações para atualizar as qualidades das qualidades\n","  actionString = turnActionToString(action)\n","  currentStateActionQuality = grid[agentPosition[0]][agentPosition[1]][actionString]\n","  updatedStateActionQuality = updateCellQuality(currentStateActionQuality)\n","  grid[agentPosition[0]][agentPosition[1]][actionString] = updatedStateActionQuality\n","\n","  agentPosition = nextPosition"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPNlhdoJTPc2t6qBlJN+Dh7","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
